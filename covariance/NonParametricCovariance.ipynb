{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "train_set = pd.read_csv('train.csv')\n",
    "val_set = pd.read_csv('val.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [02:55<00:00, 122.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RectangularGaussianFilterCovModel -4.061573553309507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RectangularGaussianFilterCovModel(CovarianceModel):\n",
    "    \"\"\"\n",
    "    This model estimates var[long] and var[lat] independently with the same technique (we don't yet estimate cov[long, lat]):\n",
    "\n",
    "    Train:\n",
    "    * Create a space with a dimension for each latent variable, and a dimension for var[X]\n",
    "    * For each point in the training set, add a vector to the space with the latent variables and where var[X] is estimated by\n",
    "      the squared prediction error in X (ie we're assuming a z-score of 1 treating X as a univariate normal distribution)\n",
    "\n",
    "    Evaluate:\n",
    "    * We are given some latent variables\n",
    "    * Compute the average of all the var[X]s in the space, weighted by a Gaussian filter / window that is centred on the latent variables\n",
    "\n",
    "    Then we return the covariance matrix with the average var[X]s on the diagonal and 0s everywhere else\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.space = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        residuals = df_residuals(train_set).T\n",
    "        # scale the latent variables to keep the variance of each dimension roughly the same\n",
    "        self.scale = np.array([0.3, 0.5, 5])\n",
    "        self.space = np.column_stack((\n",
    "            train_set.long.to_numpy(),\n",
    "            train_set.lat.to_numpy(),\n",
    "            train_set.intensity.to_numpy(),\n",
    "            residuals[0]**2, # var[long]\n",
    "            residuals[1]**2, # var[lat]\n",
    "        ))\n",
    "        self.space[:,:3] *= self.scale\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        # create a list of weights for each point in the space\n",
    "        # the weight is the Gaussian filter / window centred on the given long/lat/intensity\n",
    "        latent_centered = self.space[:,:3] - np.array([long, lat, intensity]) * self.scale\n",
    "        weights = np.exp(-0.5 * np.sum(latent_centered**2, axis=1))\n",
    "        weights /= np.sum(weights)\n",
    "        # compute the weighted average of the var[X]s\n",
    "        weighted_var_long = np.sum(weights * self.space[:,3])\n",
    "        weighted_var_lat = np.sum(weights * self.space[:,4])\n",
    "        return np.array([[weighted_var_long, 0], [0, weighted_var_lat]])\n",
    "\n",
    "print(f\"\\nRectangularGaussianFilterCovModel {RectangularGaussianFilterCovModel().assess_geo_mean_log_likelihood(train_set, test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [02:20<00:00, 153.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GaussianFilterCovModel -4.125538328293637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GaussianFilterCovModel(CovarianceModel):\n",
    "    \"\"\"\n",
    "    This model estimates var[long] and var[lat] and cov[long, lat] independently with the same technique\n",
    "\n",
    "    Train:\n",
    "    * Create a space with a dimension for each latent variable, and a dimension for each quantity we're estimating\n",
    "    * For each point in the training set, add a vector to the space with the latent variables and where var[X] is estimated by\n",
    "      the squared prediction error in X (ie we're assuming a z-score of 1 treating X as a univariate normal distribution with 0 mean)\n",
    "      and cov[X, Y] is estimated by the product of errors in X and Y (because var[X]=E[X^2] and cov[X,Y]=E[X]E[Y] with a 0 mean)\n",
    "\n",
    "    Evaluate:\n",
    "    * We are given some latent variables\n",
    "    * Compute the average of all the var[X]s in the space, weighted by a Gaussian filter / window that is centred on the latent variables\n",
    "\n",
    "    Then we return the covariance matrix with the average var[X]s on the diagonal and 0s everywhere else\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.space = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        residuals = df_residuals(train_set).T\n",
    "        self.scale = np.array([0.3, 0.5, 5])\n",
    "        self.space = np.column_stack((\n",
    "            train_set.long.to_numpy(),\n",
    "            train_set.lat.to_numpy(),\n",
    "            train_set.intensity.to_numpy(),\n",
    "            residuals[0]**2, # var[long]\n",
    "            residuals[1]**2, # var[lat]\n",
    "            residuals[0]*residuals[1], # cov[long, lat]\n",
    "        ))\n",
    "        self.space[:,:3] *= self.scale\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        # create a list of weights for each point in the space\n",
    "        # the weight is the Gaussian filter / window centred on the given long/lat/intensity\n",
    "        latent_centered = self.space[:,:3] - np.array([long, lat, intensity]) * self.scale\n",
    "        weights = np.exp(-0.5 * np.sum(latent_centered**2, axis=1))\n",
    "        weights /= np.sum(weights)\n",
    "        # compute the weighted average of the var[X]s\n",
    "        weighted_var_long = np.sum(weights * self.space[:,3])\n",
    "        weighted_var_lat = np.sum(weights * self.space[:,4])\n",
    "        weighted_cov_long_lat = np.sum(weights * self.space[:,5])\n",
    "        return np.array([[weighted_var_long, weighted_cov_long_lat], [weighted_cov_long_lat, weighted_var_lat]])\n",
    "\n",
    "print(f\"\\nGaussianFilterCovModel {GaussianFilterCovModel().assess_geo_mean_log_likelihood(train_set, test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:17<00:00, 1224.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NearestNeighborsCovModel -3.9152996999375564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "class NearestNeighborsCovModel(CovarianceModel):\n",
    "    \"\"\"\n",
    "    This model estimates var[long] and var[lat] and cov[long, lat] independently with the same technique\n",
    "\n",
    "    Train:\n",
    "    * Create a space with a dimension for each latent variable, and a dimension for each quantity we're estimating\n",
    "    * For each point in the training set, add a vector to the space with the latent variables and where var[X] is estimated by\n",
    "      the squared prediction error in X (ie we're assuming a z-score of 1 treating X as a univariate normal distribution with 0 mean)\n",
    "      and cov[X, Y] is estimated by the product of errors in X and Y (because var[X]=E[X^2] and cov[X,Y]=E[X]E[Y] with a 0 mean)\n",
    "\n",
    "    Evaluate:\n",
    "    * We are given some latent variables\n",
    "    * Compute the average of all the var[X]s in the space, weighted by a Gaussian filter / window that is centred on the latent variables\n",
    "\n",
    "    Then we return the covariance matrix with the average var[X]s on the diagonal and 0s everywhere else\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.space = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        residuals = df_residuals(train_set).T\n",
    "        self.scale = np.array([0.3, 0.5, 5])\n",
    "        self.space = np.column_stack((\n",
    "            train_set.long.to_numpy(),\n",
    "            train_set.lat.to_numpy(),\n",
    "            train_set.intensity.to_numpy(),\n",
    "            residuals[0]**2, # var[long]\n",
    "            residuals[1]**2, # var[lat]\n",
    "            residuals[0]*residuals[1], # cov[long, lat]\n",
    "        ))\n",
    "        self.space[:,:3] *= self.scale\n",
    "        self.neigh = KNeighborsRegressor(n_neighbors=2000)\n",
    "        self.neigh.fit(self.space[:,:3], self.space[:,3:])\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        x = np.array([long, lat, intensity]) * self.scale\n",
    "        params = self.neigh.predict(x.reshape(1, -1))[0]\n",
    "        return np.array([[params[0], params[2]], [params[2], params[1]]])\n",
    "\n",
    "print(f\"\\nNearestNeighborsCovModel {NearestNeighborsCovModel().assess_geo_mean_log_likelihood(train_set, test_set)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

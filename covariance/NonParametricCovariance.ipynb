{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from abc import abstractmethod\n",
    "from lib import CovarianceModel, Hemisphere, df_residuals, pretty_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "val_set = pd.read_csv('val.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianProcessCovBaseModel(CovarianceModel):\n",
    "    \"\"\"\n",
    "    This model estimates var[long] and var[lat] and cov[long, lat] independently with the same technique\n",
    "\n",
    "    Train:\n",
    "    * Create a space with a dimension for each latent variable, and a dimension for each quantity we're estimating\n",
    "    * For each point in the training set, add a vector to the space with the latent variables and where var[X] is estimated by\n",
    "      the squared prediction error in X (ie we're assuming a z-score of 1 treating X as a univariate normal distribution with 0 mean)\n",
    "      and cov[X, Y] is estimated by the product of errors in X and Y (because var[X]=E[X^2] and cov[X,Y]=E[X]E[Y] with a 0 mean)\n",
    "\n",
    "    Evaluate:\n",
    "    * We are given some latent variables\n",
    "    * Compute the average of all the var[X]s in the space, weighted by a covariance function centred on the latent variables\n",
    "\n",
    "    Then we return the covariance matrix with the average var[X]s on the diagonal and 0s everywhere else\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.space = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        residuals = df_residuals(train_set).T\n",
    "        self.scale = np.array([0.5, 1, 3])/5\n",
    "        self.space = np.column_stack((\n",
    "            train_set.long.to_numpy(),\n",
    "            train_set.lat.to_numpy(),\n",
    "            train_set.intensity.to_numpy(),\n",
    "            residuals[0]**2, # var[long]\n",
    "            residuals[1]**2, # var[lat]\n",
    "            residuals[0]*residuals[1], # cov[long, lat]\n",
    "        ))\n",
    "        self.space[:,:3] *= self.scale\n",
    "        print(\"Finished training\")\n",
    "\n",
    "    @property\n",
    "    def latent_space_scaled(self) -> np.ndarray:\n",
    "        return self.space[:,:3]\n",
    "\n",
    "    # this calculates the covariance in the regression variables between different latent points\n",
    "    # eg cov[var[long] at latent point 1, var[long] at latent point 2]\n",
    "    # it does this at every point in the space to get a non-normalised weight vector\n",
    "    # where each entry is weight_i = cov[var[long] at latent point i, var[long] at latent point we're evaluating at]\n",
    "    # note that it's a different covariance! it's covariance in the Gaussian Process sense\n",
    "    @abstractmethod\n",
    "    def covariance_function(self, latent_scaled: np.ndarray) -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        # create a list of weights for each point in the space\n",
    "        # the weight is the Gaussian filter / window centred on the given long/lat/intensity\n",
    "        latent_scaled = np.array([long, lat, intensity]) * self.scale\n",
    "        weights = self.covariance_function(latent_scaled)\n",
    "        weights /= np.sum(weights)\n",
    "        # compute the weighted average of the var[X]s\n",
    "        weighted_var_long = np.sum(weights * self.space[:,3])\n",
    "        weighted_var_lat = np.sum(weights * self.space[:,4])\n",
    "        weighted_cov_long_lat = np.sum(weights * self.space[:,5])\n",
    "        return np.array([[weighted_var_long, weighted_cov_long_lat], [weighted_cov_long_lat, weighted_var_lat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [02:13<00:00, 161.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessGaussianFilterCovModel:\n",
      "  log likelihood: -83665\n",
      "  log geo mean likelihood: -3.883\n",
      "  geo mean p density: 0.02058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GaussianProcessGaussianFilterCovModel(GaussianProcessCovBaseModel):\n",
    "    def covariance_function(self, latent_scaled: np.ndarray) -> np.ndarray:\n",
    "        return np.exp(-0.5 * np.sum((self.latent_space_scaled - latent_scaled)**2, axis=1))\n",
    "\n",
    "GaussianProcessGaussianFilterCovModel.assess(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [02:15<00:00, 159.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianProcessExponentialFilterCovModel:\n",
      "  log likelihood: -83699\n",
      "  log geo mean likelihood: -3.885\n",
      "  geo mean p density: 0.02055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GaussianProcessExponentialFilterCovModel(GaussianProcessCovBaseModel):\n",
    "    def covariance_function(self, latent_scaled: np.ndarray) -> np.ndarray:\n",
    "        return np.exp(-np.linalg.norm(self.latent_space_scaled - latent_scaled, axis=1)*2)\n",
    "\n",
    "GaussianProcessExponentialFilterCovModel.assess(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n",
      "Finished fitting neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:37<00:00, 581.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestNeighborsCovModel:\n",
      "  log likelihood: -84597\n",
      "  log geo mean likelihood: -3.927\n",
      "  geo mean p density: 0.01971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class NearestNeighborsCovModel(GaussianProcessCovBaseModel):\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        super().train(train_set)\n",
    "        self.neigh = NearestNeighbors(n_neighbors=2000).fit(self.space[:,:3])\n",
    "        print(\"Finished fitting neighbors\")\n",
    "\n",
    "    def covariance_function(self, latent_scaled: np.ndarray) -> np.ndarray:\n",
    "        # the weights are uniform across the nearest neighbors\n",
    "        indices = self.neigh.kneighbors([latent_scaled], return_distance=False)[0]\n",
    "        weights = np.zeros(len(self.space))\n",
    "        weights[indices] = 1 / len(indices)\n",
    "        return weights\n",
    "\n",
    "NearestNeighborsCovModel.assess(train_set, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

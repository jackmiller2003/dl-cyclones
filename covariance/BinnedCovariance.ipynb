{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib import CovarianceModel, Hemisphere, df_residuals, pretty_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "val_set = pd.read_csv('val.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.398, 0.010], [0.010, 0.268]]\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:02<00:00, 8858.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalCovModel:\n",
      "  log likelihood: -90490\n",
      "  log geo mean likelihood: -4.200\n",
      "  geo mean p density: 0.01499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GlobalCovModel(CovarianceModel):\n",
    "    def __init__(self):\n",
    "        self.cov = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        self.cov = np.cov(df_residuals(train_set).T, ddof=1)\n",
    "        print(pretty_cov(self.cov))\n",
    "        print('Training complete')\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        return self.cov\n",
    "\n",
    "GlobalCovModel.assess(train_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South -5.0: [[0.650, -0.052], [-0.052, 0.413]]\n",
      "North -5.0: [[0.933, 0.024], [0.024, 0.403]]\n",
      "South -4.0: [[0.793, -0.179], [-0.179, 0.547]]\n",
      "North -4.0: [[1.863, 0.133], [0.133, 0.580]]\n",
      "South -3.0: [[0.301, -0.017], [-0.017, 0.257]]\n",
      "North -3.0: [[0.292, 0.014], [0.014, 0.241]]\n",
      "South -2.0: [[0.462, -0.079], [-0.079, 0.291]]\n",
      "North -2.0: [[0.541, 0.055], [0.055, 0.281]]\n",
      "South -1.0: [[0.346, -0.029], [-0.029, 0.277]]\n",
      "North -1.0: [[0.327, 0.022], [0.022, 0.261]]\n",
      "South 0.0: [[0.344, -0.038], [-0.038, 0.277]]\n",
      "North 0.0: [[0.340, 0.042], [0.042, 0.238]]\n",
      "South 1.0: [[0.304, -0.039], [-0.039, 0.234]]\n",
      "North 1.0: [[0.335, 0.031], [0.031, 0.220]]\n",
      "South 2.0: [[0.308, -0.029], [-0.029, 0.221]]\n",
      "North 2.0: [[0.288, 0.041], [0.041, 0.201]]\n",
      "South 3.0: [[0.251, -0.035], [-0.035, 0.210]]\n",
      "North 3.0: [[0.223, 0.028], [0.028, 0.182]]\n",
      "South 4.0: [[0.219, -0.029], [-0.029, 0.171]]\n",
      "North 4.0: [[0.194, 0.031], [0.031, 0.168]]\n",
      "South 5.0: [[0.186, -0.045], [-0.045, 0.237]]\n",
      "North 5.0: [[0.184, 0.052], [0.052, 0.165]]\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:02<00:00, 8747.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinnedCovModel:\n",
      "  log likelihood: -84599\n",
      "  log geo mean likelihood: -3.927\n",
      "  geo mean p density: 0.01971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BinnedCovModel(CovarianceModel):\n",
    "    def __init__(self):\n",
    "        self.covs = {}\n",
    "        self.intensities = [-5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        self.hemispheres = [Hemisphere.South, Hemisphere.North]\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        # bin the data by hemisphere and intensity at the start of the time window\n",
    "        # and calculate the sample covariance matrix for each bin\n",
    "        for inten in self.intensities:\n",
    "            correct_inten = train_set[train_set.intensity == inten]\n",
    "            for hemi in self.hemispheres:\n",
    "                subset = correct_inten[correct_inten.lat > 0] if hemi == Hemisphere.North else correct_inten[correct_inten.lat < 0]\n",
    "                self.covs[hemi, inten] = np.cov(df_residuals(subset).T, ddof=1)\n",
    "        for hemi, inten in self.covs:\n",
    "            print(f\"{hemi} {inten}: {pretty_cov(self.covs[hemi, inten])}\")\n",
    "        print('Training complete')\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        return self.covs[Hemisphere.latitude(lat), intensity]\n",
    "\n",
    "BinnedCovModel.assess(train_set, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lib import CovarianceModel, Hemisphere, df_residuals, pretty_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('train.csv')\n",
    "val_set = pd.read_csv('val.csv')\n",
    "test_set = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.374, 0.028], [0.028, 0.737]]\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:01<00:00, 17098.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalCovModel:\n",
      "  log likelihood: -63997\n",
      "  log geo mean likelihood: -2.971\n",
      "  geo mean p density: 0.05128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class GlobalCovModel(CovarianceModel):\n",
    "    def __init__(self):\n",
    "        self.cov = None\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        self.cov = np.cov(df_residuals(train_set).T, ddof=1)\n",
    "        print(pretty_cov(self.cov))\n",
    "        print('Training complete')\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        return self.cov\n",
    "\n",
    "GlobalCovModel.assess(val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "South -5.0: [[2.388, -0.389], [-0.389, 1.424]]\n",
      "North -5.0: [[2.434, 0.088], [0.088, 1.008]]\n",
      "South -4.0: [[1.263, -0.270], [-0.270, 1.229]]\n",
      "North -4.0: [[7.757, 1.778], [1.778, 2.306]]\n",
      "South -3.0: [[0.514, -0.047], [-0.047, 0.513]]\n",
      "North -3.0: [[1.129, 0.098], [0.098, 0.700]]\n",
      "South -2.0: [[0.975, -0.815], [-0.815, 1.027]]\n",
      "North -2.0: [[1.434, 0.068], [0.068, 1.007]]\n",
      "South -1.0: [[1.403, 0.011], [0.011, 0.693]]\n",
      "North -1.0: [[1.323, 0.160], [0.160, 0.686]]\n",
      "South 0.0: [[1.652, -0.110], [-0.110, 0.788]]\n",
      "North 0.0: [[0.980, 0.074], [0.074, 0.582]]\n",
      "South 1.0: [[1.396, -0.489], [-0.489, 0.843]]\n",
      "North 1.0: [[0.833, 0.105], [0.105, 0.638]]\n",
      "South 2.0: [[0.724, -0.006], [-0.006, 0.512]]\n",
      "North 2.0: [[0.591, 0.047], [0.047, 0.392]]\n",
      "South 3.0: [[0.703, -0.068], [-0.068, 0.354]]\n",
      "North 3.0: [[0.592, 0.134], [0.134, 0.429]]\n",
      "South 4.0: [[1.470, -0.204], [-0.204, 0.479]]\n",
      "North 4.0: [[0.477, 0.161], [0.161, 0.428]]\n",
      "South 5.0: [[0.058, -0.008], [-0.008, 0.045]]\n",
      "North 5.0: [[0.382, 0.029], [0.029, 0.172]]\n",
      "Training complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21544/21544 [00:01<00:00, 17386.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinnedCovModel:\n",
      "  log likelihood: -62118\n",
      "  log geo mean likelihood: -2.883\n",
      "  geo mean p density: 0.05595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BinnedCovModel(CovarianceModel):\n",
    "    def __init__(self):\n",
    "        self.covs = {}\n",
    "        self.intensities = [-5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "        self.hemispheres = [Hemisphere.South, Hemisphere.North]\n",
    "\n",
    "    def train(self, train_set: pd.DataFrame):\n",
    "        # bin the data by hemisphere and intensity at the start of the time window\n",
    "        # and calculate the sample covariance matrix for each bin\n",
    "        for inten in self.intensities:\n",
    "            correct_inten = train_set[train_set.intensity == inten]\n",
    "            for hemi in self.hemispheres:\n",
    "                subset = correct_inten[correct_inten.lat > 0] if hemi == Hemisphere.North else correct_inten[correct_inten.lat < 0]\n",
    "                self.covs[hemi, inten] = np.cov(df_residuals(subset).T, ddof=1)\n",
    "        for hemi, inten in self.covs:\n",
    "            print(f\"{hemi} {inten}: {pretty_cov(self.covs[hemi, inten])}\")\n",
    "        print('Training complete')\n",
    "\n",
    "    def estimate(self, long: float, lat: float, intensity: float) -> np.ndarray:\n",
    "        return self.covs[Hemisphere.latitude(lat), intensity]\n",
    "\n",
    "BinnedCovModel.assess(val_set, test_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit ('shims': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4208b2b7c9844192a678902d091a2d82284df5aa62856f2ea1c7a8dba9e9177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4432c864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "10d0b639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ensemble' from '/Users/oliver/Projects/dl-cyclones/ensemble/ensemble.py'>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import ensemble\n",
    "importlib.reload(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8a3dedad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100) (200, 2)\n",
      "(50, 100) (50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate high dimensional Gaussian noise with nonlinear relationships between the source and target vectors\n",
    "\n",
    "import math\n",
    "\n",
    "def get_data_point():\n",
    "#     latent = np.random.randn(10)\n",
    "#     noise = np.random.randn(2) * latent[3] + latent[5]/2\n",
    "#     target = np.array([\n",
    "#         latent[0] + latent[1]**2 - 10 * math.sqrt(abs(latent[4])),\n",
    "#         latent[7]**3 - 7 * latent[0]\n",
    "#     ]) + noise\n",
    "#     source = np.resize(latent, 100) * 5 - 10 * np.resize(latent**2, 100)\n",
    "    source = np.random.randn(100)\n",
    "    noise = np.random.randn(2)\n",
    "    target = np.array([\n",
    "        source[0:10].mean() + (source[11:20]**2).mean() / (source[21:30].mean() + 1) - np.abs(source[31:40]).mean(),\n",
    "        source[7:21].mean() + (source[11:20:2]**2).mean() / (source[27:33].mean() + 1) - np.abs(source[35:47]).mean(),\n",
    "    ]) + noise\n",
    "    return source, target, noise\n",
    "\n",
    "def transpose_tuples(arr):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    for x, y, z in arr:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "    return np.array(xs), np.array(ys), np.array(zs)\n",
    "\n",
    "# each row is the feature vector for a time interval\n",
    "train_feature_vectors, train_label_vectors, train_noise = transpose_tuples([get_data_point() for i in range(200)])\n",
    "print(train_feature_vectors.shape, train_label_vectors.shape)\n",
    "\n",
    "valid_feature_vectors, valid_label_vectors, valid_noise = transpose_tuples([get_data_point() for i in range(50)])\n",
    "print(valid_feature_vectors.shape, valid_label_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "174ecc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145.56469228287506"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bound the loss\n",
    "min_loss = haversine_loss(train_label_vectors, train_label_vectors - train_noise).mean()\n",
    "min_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8a0cd541",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train all of the models in model_classes on the training data\n",
    "def train(model_class):\n",
    "    model = model_class()\n",
    "    print(\"\\n\\nTraining model \" + model.NAME)\n",
    "    model.train(train_feature_vectors, valid_feature_vectors, train_label_vectors, valid_label_vectors, verbose=True)\n",
    "    print(\"Saving model \" + model.NAME + \" which had validation mean km error of \" + str(model.mean_km))\n",
    "    model.save(model.NAME)\n",
    "# for model_class in ensemble.model_classes: train_model(model_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "be5ecd26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model ANN\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_86 (Dense)            (None, 256)               25856     \n",
      "                                                                 \n",
      " batch_normalization_56 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_57 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,210\n",
      "Trainable params: 93,186\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 21:25:11.760178: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 198ms/step - loss: 238.2637 - val_loss: 188.3912\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 227.0731 - val_loss: 188.7443\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 21:25:12.200181: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 38ms/step - loss: 191.9930 - val_loss: 188.6539\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 187.1098 - val_loss: 188.0447\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 177.2401 - val_loss: 187.6818\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 175.0824 - val_loss: 187.4015\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 160.4684 - val_loss: 186.9798\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 165.1616 - val_loss: 186.6308\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 146.8151 - val_loss: 186.3603\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 152.5287 - val_loss: 186.3961\n",
      "validation mean km error: 186.4\n",
      "Saving model ANN which had validation mean km error of 186.39609945199902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 21:25:12.830054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.ANNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a578e592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model ADA\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "fit models\n",
      "[{'n_estimators': 300}, {'n_estimators': 300}]\n",
      "fit best model\n",
      "validation mean km error: 182.2\n",
      "Saving model ADA which had validation mean km error of 182.1586788573517\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.AdaBoostModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1865564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model KNN\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "fit models\n",
      "fit best model\n",
      "validation mean km error: 184.3\n",
      "Saving model KNN which had validation mean km error of 184.31054377885778\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.KNNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e962221e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model RF\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit models\n",
      "fit best model\n",
      "validation mean km error: 186.2\n",
      "Saving model RF which had validation mean km error of 186.20463279667783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.RandomForestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "60a4f202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model XGB\n",
      "[21:25:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fit model\n",
      "validation mean km error: 203.1\n",
      "Saving model XGB which had validation mean km error of 203.14008209110415\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.XGBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4501e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save/load models, check they work after loading from disk\n",
    "models = [model_class.load(model_class.NAME) for model_class in ensemble.model_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "843f6c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min possible loss: 145.56\n",
      "ANN      val loss: 186.40\n",
      "ADA      val loss: 182.16\n",
      "KNN      val loss: 184.31\n",
      "RF       val loss: 186.20\n",
      "XGB      val loss: 203.14\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min possible loss: {min_loss:.2f}\")\n",
    "for model in models:\n",
    "    print(f\"{model.NAME:<8} val loss: {model.mean_km:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e11febfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ANN', 'ADA', 'KNN', 'RF', 'XGB']\n",
      "[(50, 2), (50, 2), (50, 2), (50, 2), (50, 2)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, 50, 2)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble these models together and see how the ensemble loss compares\n",
    "preds = np.array([model.predict(valid_feature_vectors) for model in models])\n",
    "print([model.NAME for model in models])\n",
    "print([preds[i].shape for i in range(len(preds))])\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "57ddc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.51402616749732"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = np.swapaxes(np.swapaxes(preds, 0, 2), 0, 1).mean(axis=2)\n",
    "haversine_loss(ensemble_preds, valid_label_vectors).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

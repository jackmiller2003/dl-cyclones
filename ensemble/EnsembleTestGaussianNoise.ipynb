{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4806e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "052ba7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ensemble' from '/Users/oliver/Projects/dl-cyclones/ensemble/ensemble.py'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import ensemble\n",
    "importlib.reload(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d9477f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 100) (200, 2)\n",
      "(50, 100) (50, 2)\n"
     ]
    }
   ],
   "source": [
    "# Generate high dimensional Gaussian noise with nonlinear relationships between the source and target vectors\n",
    "\n",
    "import math\n",
    "\n",
    "def get_data_point():\n",
    "    latent = np.random.randn(10)\n",
    "    target = [latent[0] + latent[1]**2 - 10 * math.sqrt(abs(latent[4])), latent[7]**3 - 7 * latent[0]]\n",
    "    source = np.random.randn(100) + np.resize(latent, 100) * 5 - 10 * np.resize(latent**2, 100)\n",
    "    return np.array(source), np.array(target)\n",
    "\n",
    "def transpose_tuples(arr):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for x, y in arr:\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# each row is the feature vector for a time interval\n",
    "train_feature_vectors, train_label_vectors = transpose_tuples([get_data_point() for i in range(200)])\n",
    "print(train_feature_vectors.shape, train_label_vectors.shape)\n",
    "valid_feature_vectors, valid_label_vectors = transpose_tuples([get_data_point() for i in range(50)])\n",
    "print(valid_feature_vectors.shape, valid_label_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8d74c20d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train all of the models in model_classes on the training data\n",
    "def train(model_class):\n",
    "    model = model_class()\n",
    "    print(\"\\n\\nTraining model \" + model.name)\n",
    "    model.train(train_feature_vectors, valid_feature_vectors, train_label_vectors, valid_label_vectors, verbose=True)\n",
    "    print(\"Saving model \" + model.name + \" which had validation mean km error of \" + str(model.mean_km))\n",
    "    model.save(model.name)\n",
    "# for model_class in ensemble.model_classes: train_model(model_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dc4f8126",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model ANN\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_74 (Dense)            (None, 256)               25856     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,210\n",
      "Trainable params: 93,186\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:22:19.524291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 219ms/step - loss: 1204.8435 - val_loss: 1391.7778\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1177.9729 - val_loss: 1370.9840\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:22:19.994478: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 34ms/step - loss: 1144.1500 - val_loss: 1324.5270\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1127.6006 - val_loss: 1287.0176\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1104.6199 - val_loss: 1289.2559\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1096.1556 - val_loss: 1268.4690\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1087.5112 - val_loss: 1265.2965\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1076.5559 - val_loss: 1272.6904\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 1080.1393 - val_loss: 1289.3103\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 1075.5795 - val_loss: 1298.9236\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c0adc160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 20:22:20.625124: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "WARNING:tensorflow:5 out of the last 23 calls to <function Model.make_predict_function.<locals>.predict_function at 0x2c0adc160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 2) (50, 2)\n",
      "validation mean km error: 1298.9\n",
      "Saving model ANN which had validation mean km error of 1298.9237932362075\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.ANNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a205109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model ADA\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "fit models\n",
      "[{'n_estimators': 300}, {'n_estimators': 30}]\n",
      "fit best model\n",
      "validation mean km error: 645.5\n",
      "Saving model ADA which had validation mean km error of 645.5279099356893\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.AdaBoostModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "969994e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model KNN\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "fit models\n",
      "fit best model\n",
      "validation mean km error: 718.3\n",
      "Saving model KNN which had validation mean km error of 718.3308708195526\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.KNNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea81e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model RF\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit models\n",
      "fit best model\n",
      "validation mean km error: 731.0\n",
      "Saving model RF which had validation mean km error of 730.9843597237633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.RandomForestModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53275c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training model XGB\n",
      "[20:29:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-11.0-arm64-3.8/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "fit model\n",
      "validation mean km error: 756.8\n",
      "Saving model XGB which had validation mean km error of 756.7613833007123\n"
     ]
    }
   ],
   "source": [
    "train(ensemble.XGBModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f09694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Save/load models, check they work after loading from disk\n",
    "# Calculate bounds on loss\n",
    "# Ensemble these models together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

distributed.worker - WARNING - Compute Failed
Function:  f
args:      (['1979-02-28 15:00:00', '1979-02-28 17:00:00', '1979-02-28 18:00:00', '1979-02-28 21:00:00', '1979-02-28 23:00:00', '1979-03-01 00:00:00'], [(-20.3775, 149.982), (-20.3561, 149.676), (-20.3483, 149.536), (-20.3357, 149.168), (-20.3193, 148.956), (-20.3044, 148.858)])
kwargs:    {}
Exception: "KeyError('1979-03-01 00:00:00')"

Traceback (most recent call last):
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3361, in get_loc
    return self._engine.get_loc(casted_key)
  File "pandas/_libs/index.pyx", line 429, in pandas._libs.index.DatetimeEngine.get_loc
  File "pandas/_libs/index.pyx", line 462, in pandas._libs.index.DatetimeEngine.get_loc
KeyError: Timestamp('1979-03-01 00:00:00')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/pandas/core/indexes/datetimes.py", line 703, in get_loc
    return Index.get_loc(self, key, method, tolerance)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/pandas/core/indexes/base.py", line 3363, in get_loc
    raise KeyError(key) from err
KeyError: Timestamp('1979-03-01 00:00:00')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/156/jm0124/dl-cyclones/reanalysis/test_for_cpu.py", line 69, in <module>
    get_some_cyclones_list(cyclones)
  File "/home/156/jm0124/dl-cyclones/reanalysis/test_for_cpu.py", line 63, in get_some_cyclones_list
    job(list_of_tracks[n])
  File "/home/156/jm0124/dl-cyclones/reanalysis/test_for_cpu.py", line 47, in job
    cyclone = xarray.concat(chunks, "time").to_numpy()
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/concat.py", line 220, in concat
    first_obj, objs = utils.peek_at(objs)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/utils.py", line 193, in peek_at
    gen = iter(iterable)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/dask/bag/core.py", line 1470, in __iter__
    return iter(self.compute())
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/dask/base.py", line 290, in compute
    (result,) = compute(self, traverse=False, **kwargs)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/dask/base.py", line 573, in compute
    results = schedule(dsk, keys, **kwargs)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/client.py", line 3010, in get
    results = self.gather(packed, asynchronous=asynchronous, direct=direct)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/client.py", line 2162, in gather
    return self.sync(
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/utils.py", line 311, in sync
    return sync(
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/utils.py", line 378, in sync
    raise exc.with_traceback(tb)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/utils.py", line 351, in f
    result = yield future
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/tornado/gen.py", line 762, in run
    value = future.result()
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/client.py", line 2025, in _gather
    raise exception.with_traceback(traceback)
  File "/home/156/jm0124/dl-cyclones/reanalysis/test_for_cpu.py", line 40, in f
    return lib.track_to_ndarray_xr(
  File "/home/156/jm0124/dl-cyclones/reanalysis/track_to_ndarray.py", line 98, in track_to_ndarray_xr
    res.append(sample_window(ds.sel(time=time), degree_window, lat, lon))
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/dataset.py", line 2501, in sel
    pos_indexers, new_indexes = remap_label_indexers(
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/coordinates.py", line 421, in remap_label_indexers
    pos_indexers, new_indexes = indexing.remap_label_indexers(
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/indexing.py", line 121, in remap_label_indexers
    idxr, new_idx = index.query(labels, method=method, tolerance=tolerance)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/xarray/core/indexes.py", line 241, in query
    indexer = self.index.get_loc(label_value)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/pandas/core/indexes/datetimes.py", line 705, in get_loc
    raise KeyError(orig_key) from err
KeyError: '1979-03-01 00:00:00'
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999994277954105 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999994277954105 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998092651367 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999999237060547 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999999237060547 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999982833862306 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999999237060547 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999999237060547 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998474121094 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999999237060547 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999990463256836 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999988555908206 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.9999996185302735 seconds, killing
distributed.nanny - WARNING - Worker process still alive after 3.999998664855957 seconds, killing
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/process.py", line 218, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/site-packages/distributed/process.py", line 218, in _watch_process
    assert exitcode is not None
AssertionError
Exception in thread AsyncProcess Dask Worker process (from Nanny) watch process join:
Traceback (most recent call last):
  File "/g/data3/hh5/public/apps/miniconda3/envs/analysis3-22.01/lib/python3.9/threading.py", line 973, in _bootstrap_inner
